# Face Detection/Recognition

* Face detection
	* Integral images
	* Haar-like feature computation
	* Adaboost
	* Cascade of Classifiers

* Face recognition
	* Eigen Faces
	* PCA and LDA

## Face Detection (Detecció de Cares)

L'objectiu és determinar **si** hi ha una cara a la imatge i **on** està (bounding box). El flux de treball típic en aquest laboratori utilitza l'algorisme de Viola-Jones basat en les següents tècniques:

### Integral Images

Mètode per representar la imatge que permet calcular la suma de píxels de qualsevol àrea rectangular en temps constant $O(1)$, independentment de la mida de l'àrea. És la base per fer ràpid el càlcul de característiques Haar.

Es fa un sumatori acomulat (`cumsum`) per tal d'anar de 0 intensitat acumulada a max

### Haar-like Features

Característiques visuals simples definides per la diferència de la suma de píxels entre regions rectangulars adjacents (blanques i negres). Detecten propietats com vores o línies (ex: la zona dels ulls és més fosca que les galtes).

- **Càlcul:** Utilitza la **Integral Image** per obtenir el valor de la característica de forma instantània.
    
- **Tipus:** Poden ser de 2 rectangles (vertical/horitzontal), 3 rectangles o 4 rectangles.
    

![[HaarExample.jpg]]


Per afegir noves **Haar-like Features**, cal entendre que aquestes característiques es basen exclusivament en la **geometria rectangular** i la substracció de zones.

El procés consta de dos passos: registrar el nou tipus a l'enumeració i implementar la lògica matemàtica de les regions rectangulars.

Aquí tens els apunts per estendre la classe, utilitzant com a exemple una **Feature Centre-Envoltant (Center-Surround)**, molt útil per detectar punts o pupil·les.

### Extensió de Haar-like Features

#### 1. Definició del Nou Tipus

Primer cal afegir l'identificador a la classe `FeatureTypes` (que no es mostra al teu codi, però s'assumeix que existeix).

```python
class FeatureTypes(Enum):
    # ... tipus existents ...
    CENTER_SURROUND = 5 # Exemple de nou tipus
```

#### 2. Implementació de la Lògica (`get_score`)

Dins del mètode `get_score`, has d'afegir un nou bloc `elif` que defineixi com dividir l'àrea `(width, height)` en sub-rectangles.

Exemple: Center-Surround (Tipus 5)

Aquesta feature divideix l'àrea en una graella de 3x3. El rectangle central es resta de la suma total (o viceversa). Simula un punt brillant envoltat de fosc.

- **Geometria:** Un quadrat central ocupant 1/9 de l'àrea total.
    
- **Fórmula:** $Score = Sum(Centre) - Sum(Envoltant)$
    
- **Simplificació:** Matemàticament equivalent a $2 \times Sum(Centre) - Sum(Total)$.
    


```python
        elif self.type == FeatureType.CENTER_SURROUND:
            # Dividim l'amplada i alçada en 3 parts
            w_third = int(self.width / 3)
            h_third = int(self.height / 3)
            
            # Coordenades del quadrat central (x1, y1) i (x2, y2)
            center_tl = (self.top_left[0] + w_third, self.top_left[1] + h_third)
            center_br = (self.top_left[0] + 2 * w_third, self.top_left[1] + 2 * h_third)
            
            # 1. Calculem la suma de TOT el rectangle (l'envoltant + centre)
            total_region = sum_region(int_img, self.top_left, self.bottom_right)
            
            # 2. Calculem la suma només del CENTRE
            center_region = sum_region(int_img, center_tl, center_br)
            
            # 3. Apliquem la fórmula: Centre - Envoltant
            # Com que 'total' inclou el centre, Envoltant = Total - Centre.
            # Per tant: Centre - (Total - Centre) = 2 * Centre - Total
            score = 2 * center_region - total_region
```

### Consideracions de Disseny

- **Alineació amb la Memòria:** Les divisions (com `/3` o `/2`) han de ser `int()`. Si la finestra no és divisible exactament, es perden píxels de precisió, però és acceptable per a la velocitat de l'algorisme.
    
- **Cost Computacional:**
    
    - Una feature de **2 rectangles** requereix 6 accessos a la Integral Image (si estan optimitzats) o 2 crides a `sum_region`.
        
    - La feature **Center-Surround** proposada també és molt ràpida (només 2 crides a `sum_region`: total i centre).
        
- **Rotació:** Amb Integral Images estàndard, **no pots** afegir features rotades 45 graus fàcilment. Això requeriria una _Rotated Integral Image_ (calculada diagonalment).
    

### Resum visual de les Features

- `TWO_VERTICAL`: Vora vertical (esquerra vs dreta).
    
- `TWO_HORIZONTAL`: Vora horitzontal (dalt vs baix).
    
- `THREE_HORIZONTAL`: Línia (fosc-clar-fosc o viceversa).
    
- `FOUR`: Diagonal (tauler d'escacs).
    
- `CENTER_SURROUND` (Nova): Punt (centre vs perifèria).

### Adaboost

Meta-algorisme d'aprenentatge automàtic (Boosting). El seu objectiu és seleccionar un petit conjunt de característiques Haar rellevants d'entre milers de possibles.

- **Com funciona:** Combina molts "classificadors febles" (que només endevinen una mica millor que l'atzar) per crear un "classificador fort".
    
- **Pesos:** Assigna més pes a les imatges mal classificades en cada iteració per forçar l'algorisme a aprendre els casos difícils.
    

### Cascade of Classifiers

Estructura en forma de cascada per accelerar la detecció. En lloc d'avaluar les milers de característiques a tota la imatge, es fa per etapes.

- **Etapa 1:** Classificador molt simple. Si la finestra no passa (no sembla una cara), es descarta **immediatament**.
    
- **Etapes següents:** Només si passa la 1, s'avaluen classificadors més complexos.
    
- **Objectiu:** Rebutjar ràpidament el fons (background) per centrar el processament només en les zones prometedores.
    

---

## Face Recognition (Reconeixement de Cares)

Un cop detectada la cara, l'objectiu és identificar **de qui** és. Es basa en transformar la imatge (matriu de píxels) en un vector de característiques de baixa dimensió.

### Eigen Faces

Mètode que representa les cares com una combinació lineal d'un conjunt de "cares base" anomenades _Eigenfaces_ (cares fantasma). Aquestes cares base són els vectors propis (eigenvectors) derivats de la matriu de covariància de les imatges d'entrenament.

### PCA (Principal Component Analysis)

Mètode de reducció de dimensionalitat **no supervisat**. Projecta les cares en un espai de menor dimensió maximitzant la variància global de les dades.

```python
pca = PCA(n_components=n_components, whiten=True).fit(X_train)
X_train_pca = pca.transform(X_train)
```

#### Paràmetres Clau

- `n_components` (int): Nombre de components principals (Eigenfaces) a mantenir.
    
    - **Com s'utilitza:** Un nombre massa baix perd informació (cares borroses); un nombre massa alt inclou soroll.
        
- `whiten` (bool): Si és `True`, normalitza els components perquè tinguin variància unitària (útil per a classificadors posteriors).
    

### LDA (Linear Discriminant Analysis)

Mètode de reducció de dimensionalitat **supervisat**. A diferència del PCA, el LDA utilitza les etiquetes (la identitat de la persona) durant l'entrenament.

```python
clf_lda = KNeighborsClassifier(n_neighbors=optimal_k)
clf_lda.fit(X_train_lda, y_train)
```

#### Paràmetres Clau

- **Objectiu:** Busca una projecció que **maximitzi** la distància entre classes (diferents persones) i **minimitzi** la distància dins de la mateixa classe (fotos de la mateixa persona).
    
- **Comparació:** Generalment, LDA ofereix millor precisió (`accuracy_lda`) que PCA per a tasques de classificació, ja que "sap" quines característiques distingeixen millor una persona d'una altra.
    