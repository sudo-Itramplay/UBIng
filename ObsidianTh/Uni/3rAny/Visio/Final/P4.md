# Template Matching

Mètodes Principals:

- HOG
- ORB
- SIFT

## HOG (Histogram of Oriented Gradients)

Descriptor de característiques que se centra en l'estructura i la forma dels objectes mitjançant la distribució de les direccions dels gradients (canvis d'intensitat). 

Ignora la informació de color i és molt robust a canvis d'il·luminació. 

És un mètode **dens** (calcula característiques a tota la imatge, no només en punts clau).

Molt utilitzat clàssicament per a detecció de vianants.

```python
from skimage import feature
fd, hog_image = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), 
                            cells_per_block=(2, 2), visualize=True)
```

### Paràmetres

- image (array): La imatge d'entrada.
    
    Normalment es converteix a escala de grisos abans de processar.
    
- orientations (int):
    
    El nombre de "bins" (cubells) en l'histograma de direccions de gradient.
    
- **Com s'utilitza:** Un valor com 9 (típic) cobreix 180 graus en intervals de 20. Un valor **més gran** captura detalls direccionals més fins (corbes suaus), però augmenta la mida del vector de característiques. Un valor **més petit** generalitza més la forma.
    
- pixels_per_cell (tuple of int):
    
    Defineix la mida de la cel·la bàsica on es calcula un histograma.
    
- **Com s'utilitza:** Valors típics són `(8, 8)` o `(16, 16)`. Una mida **més petita** captura detalls molt locals (textura fina), resultant en un vector final gegant. Una mida **més gran** captura l'estructura global (forma general) i redueix la càrrega computacional.
    
- cells_per_block (tuple of int):
    
    Defineix quantes cel·les s'agrupen per a la normalització local d'il·luminació i contrast.
    
- **Com s'utilitza:** L'estàndard és `(2, 2)`. Aquest pas és crític per a la robustesa davant canvis de llum/ombres. Modificar-ho afecta l'encavalcament (overlap) i la invariància local.
    

**Quan s'utilitza?** HOG és excel·lent per a la detecció d'objectes rígids o amb formes definides (persones, senyals de trànsit, cotxes) quan s'utilitza amb classificadors com SVM. No és ideal si l'objecte pateix rotacions grans (no és invariant a la rotació).

---

## ORB (Oriented FAST and Rotated BRIEF)

Detector i descriptor de punts clau (_keypoints_) dissenyat com una alternativa eficient i **lliure de patents** a SIFT i SURF. 

Combina el detector FAST (velocitat) i el descriptor BRIEF (binari), afegint-hi invariància a la rotació.

És extremadament ràpid i adequat per a temps real.

```python
import cv2
orb = cv2.ORB_create(nfeatures=500, scaleFactor=1.2, nlevels=8)
kp, des = orb.detectAndCompute(image_gray, None)
```

### Paràmetres

- `nfeatures` (int):
    
    El nombre màxim de punts clau (keypoints) que l'algorisme retindrà (els de millor resposta).
    
- **Com s'utilitza:** Un valor **més gran** troba més punts, útil per a escenes complexes, però augmenta el temps de processament i pot incloure punts sorollosos. Un valor **més petit** es queda només amb els punts més forts i distintius.
    
- `scaleFactor` (float > 1.0):
    
    El factor d'escala entre nivells de la piràmide d'imatges (simulació de distància).
    
- **Com s'utilitza:** `1.2` significa que cada nivell és un 20% més petit que l'anterior. Un valor **més proper a 1** crea més nivells (més precisió d'escala) però és més lent. Un valor **més gran** redueix dràsticament la imatge, perdent capacitat de detectar característiques a escales intermèdies.
    
- `nlevels` (int):
    
    El nombre de nivells a la piràmide.
    
- **Com s'utilitza:** Determina la capacitat de detectar punts a diferents mides. Si l'objecte pot aparèixer molt petit o molt gran, necessites un `nlevels` **més gran**.
    

**Quan s'utilitza?** L'opció per defecte per a aplicacions de temps real (SLAM, realitat augmentada, robòtica mòbil) i dispositius amb poca potència (Raspberry Pi, mòbils). Funciona bé si no hi ha canvis d'escala extrems o il·luminació molt complexa.

---

## SIFT (Scale-Invariant Feature Transform)

L'algorisme de referència (_gold standard_) durant anys per a la detecció de característiques. 

És molt robust a canvis d'escala, rotació i, fins a cert punt, il·luminació i punt de vista. 

Utilitza diferències de Gaussianes (DoG) per trobar punts d'interès.

És matemàticament complex i **computacionalment costós**.

```python
import cv2
sift = cv2.SIFT_create(nfeatures=0, contrastThreshold=0.04, edgeThreshold=10)
kp, des = sift.detectAndCompute(image_gray, None)
```

### Paràmetres

- `nfeatures` (int):
    
    El nombre de millors característiques a retenir.
    
- **Com s'utilitza:** `0` (per defecte) significa que les reté totes. Limitar aquest nombre és l'única manera directa de reduir el temps de còmput posterior (matching), encara que la detecció inicial es fa igualment.
    
- `contrastThreshold` (float):
    
    El llindar per filtrar punts clau amb poc contrast (regions planes o amb poca textura).
    
- **Com s'utilitza:** Un valor **més gran** elimina més punts (és més exigent), deixant només els molt forts. Un valor **més petit** permet detectar punts en imatges amb poc contrast o fosques, però augmenta el risc de detectar soroll.
    
- `edgeThreshold` (float):
    
    El llindar per filtrar respostes que semblen vores (edges) en lloc de punts (corners), similar al filtre Harris.
    
- **Com s'utilitza:** SIFT vol evitar les vores perquè són ambigües al llarg de la línia. Un valor **més gran** és més permissiu i accepta punts que s'assemblen una mica a vores. Un valor **més petit** filtra agressivament tot el que no sigui un pic clar, resultant en menys punts però més estables.
    

**Quan s'utilitza?** Quan la precisió i la robustesa són més importants que la velocitat. Ideal per a _Image Stitching_ (panoràmiques), reconstrucció 3D (Photogrammetry) i reconeixement d'objectes on es requereixi la màxima fiabilitat de _matching_.






#### Mètode `add_patch`

Marcadors:

![[2026-01-14_17-16.png]]