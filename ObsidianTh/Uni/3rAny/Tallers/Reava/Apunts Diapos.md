#  Optimitzaci√≥
Proc√®s de selecci√≥ del millor element (o conjutn) respecte un criteri

>[!info] info
>Moltes vegades el proc√®s es redueix a la cerca d'un m√†xim o m√≠nim d'una funci√≥ que representa el criteri


## M√®todes cl√†ssics 
M√®todes per trobar el model m√©s optim:

- **[[Unimodals Continues]]**
	Fem √∫s de m√®todes centrats en la derivada o gradient
	- Hi ha garanties de trobar soluci√≥
- **[[Multimodal Continua]]**
	Fem servir m√®todes estoc√†stics basats en derivades
	- **NO** hi ha garanties de trobar soluci√≥
- **Discretes**
	Hi ha m√®todes especifics, com el _Simplex_ 

>[!info] Extra
>Hi ha m√®todes estoc√†stics que serveixen per a qualsevol funci√≥

- Representem vlors en conjunts de dades de:
	- $m$ Elements
	- $n$ Caracter√≠stiques

### Model
Expressi√≥ matem√†tica $f_w$ que depen d'uns quants par√†metres $w$ i que representa de forma fidel i compacte un  aspecte de la matriu
- Ha de dependre d'un par√†metre per tal de ser un model


>[!tip] Idea Clau
>Al final optimitzem un model per obtenir els valors a i b que f√†cin que $L$ sigui m√≠nim

### Tenir en compte per un model

Aplicar directament un model d'optimitzaci√≥ pot ser perill√≤s: **Overfitting**

- En general apendre de les dades vol dir Inferir

>[!todo] Millorar Defiici√≥

>[!summary] Inferir
>Construir de baix cap a dalt
> de les dades cap el model
> - Una infer√®ncia pot ser estimar un model d'utilitat



Volem un model Compacte que ens permeti generalitzar dades

## Aprenentage de dades
### No supervisat

Donat un conjunt de dades **no etiquetades**, l'objectiu √©s trobar l'estructura subjacent o la distribuci√≥ de les dades. Volem construir la funci√≥ m√©s simple (model) que permeti **sintetitzar**, predir patrons o **generar noves mostres** coherents amb les originals.

### Supervisat
Donat un conjunt de dades **etiquetades** (parells entrada-sortida), volem construir una funci√≥ que realitzi un **mapeig** entre elles. L'objectiu √©s que, en rebre una dada nova no vista, la funci√≥ realitzi una predicci√≥ amb un **error m√≠nim** (generalitzaci√≥).


## Sobre-estimaci√≥

Per evitar el problema de la sobre estimaci√≥ utilitzem una metodologia adequada d'aprenentatge durant l'optimitzaci√≥

- Cross -Validation (grups test i set)

Per tal de fer la optimitzaci√≥ la m√®todologia m√©s utilitzada √©s el descens del gradient


---

# Recomanadors

Amb lo d'adalt  com a base, fem una aplicaci√≥.

- Els recomanadors han de cercar i descobir (els cercadors nomes cerquen)

>[!summary] Descobir
>Trobar algo que no sabies que existia

- $C$ Espai usuaris
- $S$ Espau √≠tems

Amb els recomanadors intentem m√†ximitzar la funci√≥ d'utilitat

$$
argmax[ u(c,s)]
$$

La funci√≥ d'utilitat √©s discreta, √©s una matriu $U$
$U$ No existeix, per lo que hem d'inferir  en els seus valors

## Tipus de Recomanadors

- [[ObsidianTh/Uni/3rAny/Tallers/1rParcial/PPT3/Tipus Recomanadors/Recomanacions colaboratives|Colaboratius]] - Utilitat a traves d'an√†lisi de matriu
- [[ObsidianTh/Uni/3rAny/Tallers/1rParcial/PPT3/Tipus Recomanadors/Recomanacions NO colaboratives|No colaboratius]] - Utilitat a traves de descripci√≥ del contingut dels √≠tems
- H√≠brids

Hi ha 2 tipus de colaboratius
[[ObsidianTh/Uni/3rAny/Tallers/1rParcial/PPT3/Tipus Recomanadors/Recomanacions colaboratives basats en semblan√ßa d'usuari|Recomanacions colaboratives basats en semblan√ßa d'usuari]]
[[ObsidianTh/Uni/3rAny/Tallers/1rParcial/PPT3/Tipus Recomanadors/Recomanacions colaboratives basats en semblan√ßa d'√≠tem|Recomanacions colaboratives basats en semblan√ßa d'√≠tem]]


### Semblan√ßa users
![[Pasted image 20260125115933.png]]
Recorrem Sp buscant usuaris semblants, multiplicarem la utilitat usuari amb semblan√ßa i farem suma
	La predicci√≥ es fa sobre un usuari que no t√© utilitat d'un item
	La semblan√ßa es fa sobre el conjunt on ELS DOS USUARIS tenen utilitat


### Espai prefer√®ncies

Espai dels usuaris que han valorat √≠tems

Evaluarem dist√†ncies dins aquest espai per determinar la similitud

##### M√®todes
- Dist√†ncia euclidiana: $d(\mathbf{p}, \mathbf{q}) = \sqrt{\sum_{i=1}^{n} (q_i - p_i)^2}$
- Correlaci√≥ de Pearson: $r_{xy} = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2 \sum_{i=1}^{n} (y_i - \bar{y})^2}}$

El coeficient de correlaci√≥ de Pearson calcula una mesura de
l'ajust d'un conjunt de punts a una recta. Funciona millor que la
dist√†ncia euclidiana si les components no estan ben calibrades.

#### 1. Correlaci√≥ de Pearson: L'invariant lineal

La correlaci√≥ de Pearson √©s extremadament robusta davant de transformacions lineals.

- **Invariant a la translaci√≥:** Si sumes una constant a totes les dades ($x + a$), la correlaci√≥ no canvia. Aix√≤ vol dir que no li importa on √©s "el centre" de les dades.
    
- **Invariant a l'escala (homot√®cia):** Si multipliques totes les dades per una constant positiva ($x \cdot b$, amb $b > 0$), la correlaci√≥ es mant√© igual. Per aix√≤ √©s ideal per comparar variables amb unitats diferents (ex: metres vs. quilograms).
    
- **Simetria:** $r(x, y) = r(y, x)$.
    
- **L√≠mit:** Sempre est√† acotada en l'interval $[-1, 1]$.

#### 2. Dist√†ncia Euclidiana: L'invariant r√≠gid

La dist√†ncia euclidiana conserva el valor real de l'espai f√≠sico-matem√†tic, per tant, √©s invariant als anomenats **moviments r√≠gids** (isometries):

- **Invariant a la translaci√≥:** Si mous tot el n√∫vol de punts una dist√†ncia fixa, la separaci√≥ entre ells no canvia.
    
- **Invariant a la rotaci√≥:** Si gires l'espai respecte a un eix, la dist√†ncia entre punts es mant√© (pensa en el teorema de Pit√†gores).
    
- **Sensible a l'escala:** A difer√®ncia de Pearson, **NO √©s invariant a l'escala**. Si multipliques les dades per 2, la dist√†ncia es multiplica per 2.
    
- **Propietats de m√®trica:** Compleix la desigualtat triangular ($d(x, z) \le d(x, y) + d(y, z)$), cosa que Pearson no fa (Pearson no √©s una dist√†ncia en el sentit m√®tric estricte).

>[!tip] Correlaci√≥ negativa
>Recorda que n usuari que sigui invers al altree, √©s per tant molt semblant


### Semblan√ßa Items
![[Pasted image 20260125120826.png]]
Anirem recorrent, aquest cop, cp. 0 si no tenim u, si no farem la semblanca entre els √≠tems


## Recolecci√≥ de dades

#### 1. Recol¬∑lecci√≥ Expl√≠cita

- **Definici√≥**: Requereix que l'usuari expressi les seves prefer√®ncies de manera directa i conscient.
   
- **Impacte**: Ofereix una millor personalitzaci√≥, per√≤ es considera intrusiva i pateix un biaix cap a usuaris amb opinions extremes (polaritzats).


>[!example] Exemple
> √ös d'escales num√®riques, ordenaci√≥ d'√≠tems per prefer√®ncia, comparacions entre parells o creaci√≥ de llistes de gustos. 
> 	**Exemple**: Demanar a l'usuari que puntue una pel¬∑l√≠cula de l'1 al 5.

#### 2. Recol¬∑lecci√≥ Impl√≠cita

- **Definici√≥**: Es basa en l'observaci√≥ passiva de les interaccions de l'usuari sense que aquest hagi de fer un esfor√ß addicional.

- **Impacte**: √âs un m√®tode simple i gens intrusiu que evita el biaix de polaritzaci√≥, tot i que no permet una personalitzaci√≥ tan fina com l'expl√≠cita.

>[!Example] Exemple
> Registre d'√≠tems consultats, an√†lisi del temps de perman√®ncia en cada consulta o estudi de la xarxa social de l'usuari. 
> **Exemple**: Anotar autom√†ticament quins articles ha llegit un usuari en un blog.



## M√®triques d'avaluaci√≥

La qualitat d'un sist√®ma s'ha de poder representar.
Aquestes m√®triques NO S'UTILITZEN EN L'ENTRENAMENT

**M√®trica de precisi√≥ de la predicci√≥:**
La m√®trica m√©s usada √©s _l'error absolut mig_,
 - la difer√®ncia absoluta mitja entre les avaluacions predites i les reals:

$$
MAE = \frac{ \sum_{i,j} |u'(i,j) - u(i,j)|}{N}
$$

---

# Recomanador 2

## Funci√≥ de P√®rdua

Valor a pagar per la inexactitud de les prediccions



## Classificaci√≥
En machine learning, la classificaci√≥ √©s:
-  classificar √≠tems en 2 o m√©s classes

Per aix√≤ entrenem models pq el output sigui un vector de de classificaci√≥ amb valors per classes.
- Els interpretem passant-los a probabilitat

### Softmax
Passa Puntuaci√≥ns a probabilitats
- T√© millor comportament si desrp√©s s'utilitza el descens del gradient estoc√†stic

### Cross-Entropy
Serveix per mesurar qu√® tant bona √©s la predicci√≥ del model respecte unes etiquetes

#### Binaria
Donat uns valors i dues classes dona dos probabilitats per cada¬¥

#### Multiclasse



## Factoritzaci√≥ de Matrius

A nosaltres les caracter√≠stiques per se dels usuaris i dels √¨tmes ens donen igual,
Nosaltres volem aquells factors latents que els relacionen

A part, les matrius s√≥n esencialment matrius buides, ja que la majoria d'usuaris no t√© tot el cataleg puntuat:

![[Pasted image 20260125124424.png]]


Fem una matriu $R$ en base $U$ 
En aquesta matriu:
- Rows: For√ßa de les associacions entre user i caracter√≠stica
- Col : For√ßa entre √≠tem i caracter√≠stica


## M√†quines de factoritzaci√≥

Les **Factorization Machines (FM)** es presenten com una evoluci√≥ necess√†ria per superar les limitacions dels models de Factoritzaci√≥ de Matrius (MF) convencionals. Com a marc de treball general, la seva funci√≥ principal √©s:

## UItilitats

- **Generalitzaci√≥ de Factors Latents**: Estenen l'enfocament de factors latents per permetre la integraci√≥ de qualsevol **caracter√≠stica auxiliar** arbitr√†ria que descrigui millor usuaris i √≠tems.

- **Optimitzaci√≥ del R√†nquing**: Implementen funcions de p√®rdua especialitzades que optimitzen directament l'**ordre de prefer√®ncia** (rank-order) dels productes.

- **Aprofitament del Feedback Impl√≠cit**: Estan especialment dissenyades per treballar amb dades d'interacci√≥ indirecta (com clics o temps de visualitzaci√≥), resolent el problema de la falta de valoracions expl√≠cites.


---

### Per qu√® s√≥n superiors a la MF?

Mentre que la MF cl√†ssica es limita a la interacci√≥ directa entre usuaris i √≠tems dins d'una matriu, les FM poden processar informaci√≥ de context (com l'hora, el dispositiu o metadades de l'√≠tem) de manera eficient, oferint una recomanaci√≥ molt m√©s rica i precisa.

![[Pasted image 20260125125042.png]]

## Explicaci√≥ Pr√†ctica

### 1. La Intu√Øci√≥: Caracter√≠stiques Latents

Abans de parlar de matrius, hem d'entendre **qu√® estem buscant**. A la teva pr√†ctica, has calculat similituds basant-te directament en les votacions (Euclidiana). 

Per√≤, per qu√® un usuari vota alt una pel¬∑l√≠cula?
	La teoria de la Factoritzaci√≥ de Matrius (MF) ens diu que hi ha **factors ocults** (latents) que determinen aquestes notes.

- **Exemple:** A l'usuari $U_1$ li agraden les pel¬∑l√≠cules d'acci√≥. La pel¬∑l√≠cula $I_1$ t√© molta acci√≥. Per tant, la nota ser√† alta.
    
- **El repte:** No tenim una columna que digui "Acci√≥". Hem de _descobrir_ aquests factors autom√†ticament a partir de les dades.
    

---

### 2. Descomposici√≥ de Matrius ($R \approx P \times Q^T$)

Aquesta √©s la base matem√†tica dels recomanadors moderns (abans d'entrar en _Factorization Machines_).

#### La Matriu $R$ (La teva `df_counts`)

La matriu $R$ √©s la matriu d'interaccions Usuari-√çtem.

- A la teva pr√†ctica, a l'**Exercici C**, has creat exactament aquesta matriu amb la funci√≥ `build_counts_table`.

- √âs una matriu de mida $|U| \times |D|$ (Usuaris $\times$ Items).

- **Problema:** √âs molt **dispersa** (_sparse_). La majoria de valors s√≥n `NaN` (buits) perqu√® cap usuari ha vist totes les pel¬∑l√≠cules.


#### Les Matrius $P$ i $Q$

L'objectiu √©s trobar dues matrius m√©s petites, $P$ i $Q$, que quan es multipliquin, **omplin els forats** de $R$.

1. **Matriu $P$ (Usuaris):** De mida $|U| \times K$.
    
    - Cada fila representa un usuari.
        
    - Les $K$ columnes s√≥n els **factors latents** (ex: quant li agrada l'acci√≥, el drama, etc.).
        
2. **Matriu $Q$ (√çtems):** De mida $|D| \times K$.
    
    - Cada fila representa una pel¬∑l√≠cula.
        
    - Les $K$ columnes s√≥n els mateixos factors latents, per√≤ aplicats a la pel¬∑l√≠cula (ex: quanta acci√≥ t√©, quant drama t√©...).
        

>[!example] Anotaci√≥
>Aquestes dues matrius, a la pr√†ctica no s'han fet, √©s aproximaci√≥ teorica



#### La Predicci√≥

Per saber quina nota posaria l'usuari $u$ a la pel¬∑l√≠cula $i$, fem el **producte escalar** dels seus vectors de factors latents:

$$\hat{r}_{ui} = p_u \cdot q_i^T = \sum_{k=1}^{K} p_{uk} q_{ik}$$

> **En resum:** Estem comprimint la informaci√≥ gegant i buida de la teva `df_counts` en dues taules compactes i denses que capturen l'ess√®ncia (gustos i caracter√≠stiques).

---

### 3. Factorization Machines (FM): L'Evoluci√≥

La descomposici√≥ de matrius (MF) t√© un l√≠mit: nom√©s ent√©n d'Usuaris i √çtems. Per√≤, i si volem afegir **context** (hora del dia, dispositiu, edat, g√®nere)? 
	Aqu√≠ entren les **Factorization Machines.**

#### El problema de la regressi√≥ cl√†ssica

Si volgu√©ssim capturar la relaci√≥ entre totes les variables (Usuari, √çtem, Context), necessitar√≠em una matriu de pesos $W$ gegantina ($O(d^2)$) per guardar el pes de cada parella possible. Aix√≤ √©s incomputable i necessita massa mem√≤ria.

#### La Soluci√≥ de les FM

Les FM utilitzen un truc: **Params d'interacci√≥ factoritzats**. En lloc de calcular un pes fix $W_{ij}$ per a la interacci√≥ entre la caracter√≠stica $i$ i la $j$, assignen a cada caracter√≠stica un vector latent $v$. La interacci√≥ es calcula com el producte escalar d'aquests vectors:

$$\hat{y}(x) = w_0 + \sum w_i x_i + \sum \sum (v_i \cdot v_j) x_i x_j$$

- **Avantatge:** Redueix dr√†sticament el nombre de par√†metres a estimar (de $O(d^2)$ a lineal respecte a $K$).
    
- **Connexi√≥ amb MF:** Si utilitzem FM nom√©s amb les dades d'Usuari ID i Movie ID (codificats en _one-hot_), el model √©s matem√†ticament id√®ntic a la Matrix Factorization.
    

---

### 4. Com triem la matriu R? (Teoria vs Pr√†ctica)

A la teva pr√†ctica has constru√Øt $R$ intu√Øtivament, per√≤ la teoria del PDF ens dona dues opcions segons el tipus de feedback:

#### A. Feedback Expl√≠cit (El que has fet)

- **Dades:** Votacions directes (estrelles de l'1 al 5).
    
- **La teva R:** A l'Exercici C (`Practica22025.ipynb`), la teva `df_counts` t√© valors reals (1.0, 5.0, etc.) i `NaN` on no hi ha informaci√≥.
    
- **Objectiu:** Predir els valors que falten minimitzant l'error (MSE) entre la predicci√≥ i la nota real.
    

#### B. Feedback Impl√≠cit (El que explica el PDF)

- **Dades:** Clics, visualitzacions, compres (_clicks, views, purchases_).
    
- **Problema:** No tenim "no m'agrada" (0 estrelles). Nom√©s sabem el que l'usuari HA vist. No sabem si el que NO ha vist √©s perqu√® no li agrada o perqu√® no ho coneix.
    
- **La nova R:** En lloc de fer regressi√≥ sobre notes, s'utilitza per a **r√†nquing** (ordenar productes).
    
- **Optimitzaci√≥:** S'utilitzen t√®cniques com **BPR (Bayesian Personalized Ranking)**, on l'objectiu no √©s encertar un n√∫mero, sin√≥ assegurar que els √≠tems vistos tinguin una puntuaci√≥ m√©s alta que els no vistos ($\hat{y}_{vist} > \hat{y}_{no\_vist}$).
    

### Resum Executiu

A la teva pr√†ctica **has creat la matriu $R$** directament a partir de les dades. En canvi, **no has creat les matrius $P$ i $Q$**.

El motiu √©s que el teu codi implementa un **Recomanador Basat en Mem√≤ria** (ve√Øns propers), que treballa directament amb $R$ i una matriu de similituds. Les matrius $P$ i $Q$ pertanyen als **Recomanadors Basats en Models** (Factoritzaci√≥ de Matrius), que √©s la teoria explicada al PDF per√≤ no l'algoritme que has programat.

---

### 1. La Creaci√≥ de $R$ (La Matriu d'Interaccions)

Segons la teoria (P√†gina 13 del PDF ), $R$ √©s la matriu de mida $|U| \times |D|$ que cont√© totes les puntuacions (ratings) que els usuaris han donat als √≠tems.

#### Quan i Com l'has creat al codi?

Has creat $R$ a l'**Exercici C**, dins de la funci√≥ `build_counts_table`.

1. **Origen:** Tens un DataFrame `data` (fruit del `merge` de ratings, users i movies) on cada fila √©s una interacci√≥ individual: _L'usuari X ha puntuat la peli Y amb un 5_.
    
2. **Transformaci√≥:** Utilitzes la funci√≥ `pivot_table` de Pandas. Aquesta funci√≥ agafa les files individuals i les "pivota" per crear una graella.
    
    - **√çndex (Files):** `user_id` (Cada fila √©s un Usuari, $U$).
        
    - **Columnes:** `movie_id` (Cada columna √©s una Pel¬∑l√≠cula, $D$).
        
    - **Valors:** `rating` (El contingut de la cel¬∑la $r_{ui}$).
        

**El teu codi:**

```python
# Aix√≤ √©s exactament la creaci√≥ de la matriu R
df_counts = data.pivot_table(index='user_id', columns='movie_id', values='rating', dropna=True, sort=True)
```

**Pas previ clau:** Abans de fer aix√≤ fiable per a operacions matricials (Exercici D), vas aplicar `reset_id_index`. Aix√≤ va transformar els IDs reals (ex: 1, 50, 6040) en √≠ndexs matricials consecutius (0, 1, 2... 6039), assegurant que la matriu $R$ no tingu√©s forats als √≠ndexs.

---

### 2. I les matrius $P$ i $Q$?

A la teoria (P√†gina 13 del PDF ), l'objectiu de la Factoritzaci√≥ de Matrius √©s trobar dues matrius petites ($P$ i $Q$) que, multiplicades, aproximin $R$:

$$R \approx P \times Q^T$$

- **$P$ (User Factors):** Representa els gustos dels usuaris (mida $|U| \times K$).
    
- **$Q$ (Item Factors):** Representa les caracter√≠stiques de les pel¬∑l√≠cules (mida $|D| \times K$).
    

#### Per qu√® NO les tens al codi?

A la pr√†ctica, **no has factoritzat la matriu**. En lloc de descompondre $R$ en $P$ i $Q$ (que requeriria un algoritme iteratiu com Gradient Descent, explicat a la p√†gina 16 del PDF ), has optat per un cam√≠ diferent:

1. Has agafat $R$ (`df_counts`).
    
2. Has calculat una **Matriu de Similitud** (`similarity_matrix`, Exercici F.1). Aquesta matriu ($|U| \times |U|$) diu quan s'assembla l'usuari A a l'usuari B basant-se en les seves files a $R$.
    
3. Has fet prediccions fent una **mitjana ponderada** dels ve√Øns (`weighted_average`, Exercici F.2).
    

### 3. Esquema Comparatiu: Teoria vs. La teva Pr√†ctica

Perqu√® ho vegis clar, aqu√≠ tens la difer√®ncia estructural:

|**Pas**|**M√®tode Te√≤ric (Matrix Factorization)**|**El teu M√®tode (User-Based Collaborative Filtering)**|
|---|---|---|
|**Entrada**|Dades crues (`ratings.dat`)|Dades crues (`ratings.dat`)|
|**Pas 1**|Construir $R$ (o iterar sobre les dades)|**Construir $R$ (`df_counts`)** ‚úÖ _Fet_|
|**Pas 2**|**Crear $P$ i $Q$** (inicialitzats a l'atzar)|Calcular **Similitud entre Usuaris** (Euclidiana)|
|**Pas 3**|Ajustar $P$ i $Q$ per minimitzar l'error (Gradient Descent)|Seleccionar els $m$ usuaris m√©s semblants|
|**Predicci√≥**|Multiplicar $P_{u} \times Q_{i}^T$|Mitjana de les notes dels ve√Øns semblants|

### Conclusi√≥ per a l'avaluaci√≥
- **"Com has creat R?"**: L'he creada pivotant el dataframe de logs (`data`) per tenir usuaris a les files i pel¬∑l√≠cules a les columnes (`df_counts`).
    
- **"On s√≥n P i Q?"**: En aquesta pr√†ctica **no les he calculat**. He utilitzat un algorisme _Memory-Based_ (KNN) que treballa directament comparant les files de $R$, sense necessitat de reduir la dimensionalitat en factors latents ($P$ i $Q$) com faria un algorisme _Model-Based_.

## Perqu√® √©s un Model Lineal?
Aqu√≠ fem refer√®ncia tamb√© a la eficiencia:
### 1. L'Equaci√≥ del Model

L'equaci√≥ d'una FM de grau 2 √©s:

$$\hat{y}(x) = \underbrace{w_{0} + \sum_{i=1}^{d}w_{i}x_{i}}_{\text{PART LINEAL}} + \underbrace{\sum_{i=1}^{d}\sum_{j=i+1}^{d} \langle v_i, v_j \rangle x_{i}x_{j}}_{\text{PART D'INTERACCIONS (FACTORITZADA)}}$$

On:

- $x$ √©s el vector de caracter√≠stiques (usuaris, √≠tems, context, etc.).

- $w_0$ √©s el biaix global.

- $w_i$ s√≥n els pesos de cada caracter√≠stica individual.

- $\langle v_i, v_j \rangle$ √©s el producte escalar dels vectors latents que modelen la interacci√≥ entre la caracter√≠stica $i$ i la $j$.

### 2. Per qu√® diem que t√© un comportament "Lineal"?

Encara que captura interaccions complexes (no lineals respecte a les variables originals), FM es considera sovint dins la fam√≠lia de models lineals generalitzats per dos motius clau:

- **La base √©s lineal:** Si eliminem el segon terme (les interaccions), el model √©s exactament una **Regressi√≥ Lineal** tradicional ($w_0 + w \cdot x$). Aix√≤ vol dir que FM apr√®n el pes de cada caracter√≠stica per separat (com un model lineal) a m√©s de les seves combinacions.


- **Complexitat Computacional Lineal ($O(n)$):** Aquesta √©s la clau de la seva efici√®ncia. Un model polin√≤mic est√†ndard (que el PDF anomena "quadratic linear model" ) necessitaria calcular un pes independent $W_{ij}$ per a cada parella, la qual cosa t√© una complexitat quadr√†tica $O(d^2)$ i √©s inassumible amb moltes dades.

En canvi, gr√†cies al truc de la factoritzaci√≥ ($W_{ij} \approx v_i \cdot v_j$), les FM poden calcular la part de les interaccions en **temps lineal** respecte al nombre de caracter√≠stiques ($O(k \cdot d)$).
  
>[!example]  **En resum:** 
>FM t√© la capacitat expressiva de capturar interaccions (com un nucli polin√≤mic) per√≤ mant√© l'efici√®ncia i velocitat d'entrenament i predicci√≥ d'un model lineal.


### Com fer Que FM funcioni b√© amb feedback implicit:

#### 1. Factoritzaci√≥ de Matrius (MF): 

Problemes amb el feedback impl√≠cit La formulaci√≥ est√†ndard de la MF no funciona b√© amb aquest tipus de dades.

- **El problema:** La MF est√† dissenyada originalment per a valoracions expl√≠cites (estrelles, puntuacions). Amb el feedback impl√≠cit (clics, p√†gines vistes, compres), no observem directament valoracions negatives, nom√©s infer√®ncies de comportament.

- **L'enfocament ingenu:** Si s'intenta adaptar la MF etiquetant totes les interaccions observades com a "1" i les no observades com a "0", es produeix un **desequilibri de classes sever**. At√®s que la majoria d'interaccions s√≥n no observades, aix√≤ requeriria crear milers de milions d'exemples d'entrenament "negatius", fent el proc√©s computacionalment inviable.

- **Conclusi√≥:** La formulaci√≥ cl√†ssica de MF "es trenca" o falla quan es tracta amb dades de feedback impl√≠cit.

#### 2. M√†quines de Factoritzaci√≥ (FM): 
Les FM es presenten com una soluci√≥ per superar les limitacions de la MF, ja que permeten incorporar caracter√≠stiques auxiliars (atributs d'usuari, context, etc.).

- **Flexibilitat:** A difer√®ncia de la MF, les FM poden treballar amb vectors binaris que representen usuaris i √≠tems, i augmentar-los amb dades contextuals.

- **El repte compartit:** Tot i ser m√©s potents, adaptar les FM directament al feedback impl√≠cit utilitzant funcions de p√®rdua de classificaci√≥ est√†ndard (marcant interaccions no observades com a 0) presenta els mateixos problemes de desequilibri i cost computacional que la MF.

#### Soluci√≥ - Optimitzar el Ranking (BPR)

Perqu√® tant les MF com les FM funcionin b√© amb feedback impl√≠cit, cal canviar l'objectiu: 
	en lloc d'intentar predir una puntuaci√≥ o classificar l'error, s'ha d'aprendre l'**ordre relatiu (ranking)** dels √≠tems.

La t√®cnica clau descrita als apunts per aconseguir-ho √©s el **Bayesian Personalized Ranking (BPR)**:

- **Funcionament:** En lloc de mirar un sol √≠tem, el BPR entrena el model utilitzant **parelles d'√≠tems** $(i, j)$ per a un usuari $u$. Assumeix que l'usuari prefereix un √≠tem observat ($i$) per sobre d'un √≠tem no observat ($j$).

- **Resultat:** Aix√≤ permet optimitzar directament l'ordenaci√≥ dels √≠tems sense haver de generar milions de mostres negatives expl√≠cites, solucionant el problema del feedback impl√≠cit tant per a MF com, especialment, per a la formulaci√≥ m√©s avan√ßada de les FM.

En resum, les **FM s√≥n superiors** perqu√® permeten incorporar m√©s informaci√≥ (context), per√≤ per gestionar el feedback impl√≠cit correctament, cal utilitzar una funci√≥ de p√®rdua basada en el ranking com el **BPR**.


# Recomanadors per Session

Aix√≤ √©s m√©s que res anecd√≤tic. 
Hi ha webs que fan √∫s de recomanadors per sessi√≥, ja que es considera igual d'important que els dem√©s.
Solen jugar √∫nicament amb el que veus en una √∫nica sessi√≥ i es restableix cada cop que es torna a la app

---

# Items frequents

## Possible EXC
Regles d'Associaci√≥.
## 1. Conceptes Clau i F√≥rmules

L'objectiu √©s trobar patrons freq√ºents en una base de dades de "bosses" (transaccions, documents, pacients).

### A. Definici√≥ de la Regla

Una regla t√© la forma $X \to Y$ (Exemple: $\{m, b\} \to c$).

- **Antecedent ($X$):** La part esquerra (condici√≥).
    
- **Conseq√ºent ($Y$):** La part dreta (resultat).
    

### B. Les 3 M√®triques Sagrades

Per aprovar, has de saber calcular i distingir aquestes tres:

|**M√®trica**|**F√≥rmula**|**Significat**|
|---|---|---|
|**Suport ($s$)**|$\frac{\text{N¬∫ bosses amb } X \cup Y}{\text{N¬∫ Total Bosses}}$|Freq√º√®ncia bruta. Com de com√∫ √©s la combinaci√≥?|
|**Confian√ßa ($C$)**|$\frac{\sigma(X \cup Y)}{\sigma(X)}$|Probabilitat condicional ($P(Y \mid X)$). Si tinc $X$, amb quina seguretat tinc $Y$?|
|**Inter√®s ($I$)**|$\text{Confian√ßa} - P(Y)$|Correlaci√≥ real. Elimina l'efecte de la popularitat de $Y$.|

> [!WARNING] Atenci√≥ a l'examen
> 
> Un suport o confian√ßa alts **no** garanteixen que la regla sigui √∫til. Podria ser una coincid√®ncia perqu√® $Y$ √©s molt popular. Per aix√≤ calculem l'**Inter√®s**.

---

## 2. Exemple de C√†lcul d'Examen (Pas a Pas)

**Dades:** 8 Bosses totals ($N=8$).

**Regla a avaluar:** $\{m, b\} \to c$ ("Si tenim m i b, tindrem c?")

### Pas 1: Calcular Suport de l'Antecedent ($m, b$)

Busquem bosses que tinguin $m$ **i** $b$ alhora.

- Trobades a: B1, B3, B5, B6.
    
- $\sigma(m, b) = 4$
    

### Pas 2: Calcular Suport de la Uni√≥ ($m, b, c$)

De les anteriors, quantes tenen tamb√© $c$?

- Trobades a: B1, B6.
    
- $\sigma(m, b, c) = 2$
    

### Pas 3: Calcular la Confian√ßa

$$C = \frac{\text{Suport Uni√≥}}{\text{Suport Antecedent}} = \frac{2}{4} = 0.5 \quad (50\%)$$

### Pas 4: Calcular l'Inter√®s

Primer necessitem la probabilitat base del conseq√ºent ($c$).

- $c$ apareix a: B1, B4, B6, B7, B8 (5 bosses).
    
- $P(c) = 5/8 = 0.625$
    

Ara restem:

$$I = \text{Confian√ßa} - P(c) = 0.5 - 0.625 = -0.125$$

---

## 3. Interpretaci√≥ dels Resultats

Com interpretem el n√∫mero final?

- **Inter√®s > 0 (Positiu):** **Associaci√≥ √∫til.** La pres√®ncia de $X$ fa augmentar la probabilitat de $Y$. (Ex: Bolquers $\to$ Cervesa).
    
- **Inter√®s = 0:** **Independ√®ncia.** No hi ha relaci√≥. (Ex: $X \to$ Llet, si tothom compra llet igualment).
    
- **Inter√®s < 0 (Negatiu):** **Repulsi√≥.** La pres√®ncia de $X$ fa _menys_ probable $Y$. (Ex: Pepsi $\to$ Coke; si compres una, rarament compres l'altra).
    

_En el nostre exemple (-0.125), els √≠tems tenen una lleugera repulsi√≥._

---

## 4. Aplicacions Te√≤riques (Per preguntes tipus test)

1. **Supermercats:** Col¬∑locaci√≥ de productes (cross-selling). _Ex: Cervesa i Bolquers._
    
2. **Plagi de Documents:** Si les "bosses" s√≥n frases i els √≠tems documents. Relaci√≥ molts-a-molts.
    
3. **Medicina:** Detecci√≥ d'interaccions. Bosses = pacients amb efectes secundaris, √çtems = medicaments.
    


---

# Hip√≤tesis i Infer√®ncia 

- Suposem estad√≠stica freq√ºentista

## 1. A/B Testing (Triar la millor opci√≥)

L'**A/B Testing** s'utilitza per determinar quina variant d'un element (ex: una p√†gina web) funciona millor. (difer√®ncia de mitjanes)

- **Funcionament**: El tr√†nsit s'assigna aleat√≤riament a cada variant (A o B) segons un pes predeterminat (ex: 50-50).
    
- **Persist√®ncia**: S'usen _cookies_ perqu√® l'usuari vegi sempre la mateixa versi√≥.
    
- **M√®trica**: Es registra el temps o l'acci√≥ de l'usuari per prendre una decisi√≥ basada en dades.
    
- **Hip√≤tesi Nul¬∑la ($H_0$)**: En aquest context, la posici√≥ esc√®ptica √©s que el canvi de disseny **no t√© cap efecte**.
    

---

## 2. El M√®tode del Shuffling (Validaci√≥ de la Difer√®ncia)
- Complement A/B testing
Quan comparem dues mitjanes (A vs B) i no volem o no podem usar models te√≤rics r√≠gids, usem el **Shuffling** (barrejar etiquetes).

- **Concepte**: Si la hip√≤tesi nul¬∑la √©s certa, les etiquetes (A o B) no importen. Redistribuir-les no hauria de canviar la difer√®ncia entre mitjanes.
    
- **Procediment**:
    
    1. Es barregen (_shuffling_) les etiquetes de totes les mostres.
        
    2. Es recalculen les mitjanes i la seva difer√®ncia.
        
    3. Es repeteix el proc√©s milers de vegades per construir la **distribuci√≥ mostral** de la difer√®ncia.
        
- **Decisi√≥**: Es compta quantes vegades surt una difer√®ncia m√©s gran que l'observada originalment. Si aquesta probabilitat ($p\text{-value}$) √©s baixa (normalment $< 0.05$ o $5\%$), rebutgem la casualitat.
    

---

## 3. Bootstrapping (Mesurar la incertesa)

El **Bootstrapping** s'utilitza per crear una aproximaci√≥ robusta de la distribuci√≥ d'un par√†metre (com la mitjana o un quantil) quan no tenim un model generador de dades.

- **T√®cnica Clau**: Es basa en el **mostreig aleatori amb reempla√ßament**.
    
- **Procediment**:
    
    1. Tenim una mostra de $N$ elements.
        
    2. Seleccionem $N$ elements a l'atzar d'aquesta mostra, permetent que alguns es repeteixin i altres no surtin.
        
    3. Calculem l'estad√≠stic d'inter√®s (ex: la mitjana) per a aquesta nova "mostra bootstrap".
        
    4. Repetim milers de vegades per veure com varia el resultat.
        
- **Utilitat**: Permet calcular l'**error est√†ndard** i la incertesa d'estimacions complexes, com en la regressi√≥ lineal.
    

---

>[!info] üí° Resum per a l'examen:
> - **A/B Testing**: El marc experimental per comparar variants. 
> - **Shuffling**: T√®cnica per validar si la difer√®ncia entre dos grups (A i B) √©s real o casualitat. 
> - **Bootstrapping**: T√®cnica per estimar la incertesa d'un par√†metre usant nom√©s les dades que ja tenim.

---

# Exploraci√≥ Explotaci√≥

Fer simplement un mostreig, mitjana, i explotaci√≥ infinita √©s molt porbable que ens quedem amb valors sub-optims, per aix√≤ fem servir les seguents funcions, ja que en el temps donen millor resultts

## 1. La Teoria del Softmax

El m√®tode **Softmax** √©s una estrat√®gia per convertir puntuacions num√®riques (scores) en distribucions de probabilitat. En l'√†mbit dels sistemes de recomanaci√≥ i els _bandits_ (Tragaperras), s'utilitza principalment per balancejar l'exploraci√≥ i l'explotaci√≥.

### Fonament Matem√†tic

La funci√≥ Softmax transforma un vector de valors $z$ en probabilitats que sumen 1:

$$softmax(z) = \frac{e^z}{\sum_{j=0}^{K-1} e^{z_j}}$$

- **Per qu√® no una normalitzaci√≥ simple?** El Softmax t√© un millor comportament respecte al **Gradient Descendent Estoc√†stic (SGD)** que la normalitzaci√≥ lineal.


### Softmax en el Problema del Bandit (tragaperra) (amb Temperatura)

En un escenari de _multi-armed bandits_, triem una acci√≥ $a$ en el moment $t$ segons la seva probabilitat, que dep√®n d'un par√†metre anomenat **temperatura** ($\tau$):

- **Temperatures altes ($\tau \to \infty$):** Les accions es tornen equiprobables (distribuci√≥ uniforme), fomentant l'**exploraci√≥** pura.

- **Temperatures baixes ($\tau \to 0$):** El m√®tode es torna "vora√ß" (_greedy_), seleccionant gaireb√© sempre l'opci√≥ amb millor estimaci√≥, prioritzant l'**explotaci√≥**.

---

[[#OJO AMB NO ESTACIONARIS]]

---
## 2. UCB1 (Upper Confidence Bound)

L'algorisme **UCB1** busca una via interm√®dia que vari√Ø autom√†ticament entre exploraci√≥ i explotaci√≥ incorporant la **incertesa** estad√≠sticament.

### La Regla de Decisi√≥

Escollim l'acci√≥ $a^*$ que maximitzi la suma del valor estimat i la seva incertesa:

$$a^* = \arg \max_a (Q_t(a) + U_a)$$

### C√†lcul de la Incertesa

Basat en la **cota de Hoeffding**, la incertesa ($U_a$) es calcula com:

$$U_a = \sqrt{\frac{2 \ln t}{t_a}}$$

- $t$: Nombre total de jugades fetes fins al moment.
    
- $t_a$: Nombre de vegades que hem triat l'acci√≥ $a$.
    

**Comportament:**

- Cada cop que triem $a$, $t_a$ augmenta i la incertesa **disminueix** (explotaci√≥).
    
- Quan triem altres accions, $t$ augmenta i la incertesa de $a$ **creix** logar√≠tmicament, fent que eventualment la tornem a explorar.

---
## 3. Mostreig de Thompson (Thompson Sampling)

A difer√®ncia dels m√®todes vora√ßos que usen valors puntuals, el **Mostreig de Thompson** √©s un m√®tode **estoc√†stic** que modela la **incertesa** mitjan√ßant distribucions de probabilitat.

### La Distribuci√≥ Beta

Per a recompenses bin√†ries (com _clic_ o _no clic_), s'utilitza la **distribuci√≥ Beta**, definida en l'interval $[0, 1]$ per dos par√†metres: $\alpha$ (√®xits) i $\beta$ (fracassos).

- **Valor mig:** Es calcula com $\frac{\alpha}{\alpha + \beta}$.

- **Inicialitzaci√≥:** Es comen√ßa amb $\alpha = 1, \beta = 1$, que equival a una distribuci√≥ uniforme (incertesa total).


### Funcionament de l'Algorisme

A cada pas, l'algorisme segueix aquest proc√©s:

1. **Mostreig:** Es genera un valor aleatori $v_i$ per a cada acci√≥ a partir de la seva funci√≥ Beta.

2. **Selecci√≥:** S'executa l'acci√≥ amb el valor mostrejat m√©s alt.

3. **Actualitzaci√≥:** Segons el resultat ($r$), s'actualitzen els par√†metres de l'acci√≥ triada:
    
    - Si hi ha √®xit ($r=1$): $\alpha = \alpha + 1$.
    
    - Si hi ha frac√†s ($r=0$): $\beta = \beta + 1$.
    

### Avantatges clau

- **Converg√®ncia:** A mesura que recollim dades, la distribuci√≥ es fa m√©s estreta, reduint naturalment l'exploraci√≥ i augmentant l'explotaci√≥.

- **Retroalimentaci√≥ retardada:** Supera l'algorisme UCB1 en sistemes reals on la recompensa no √©s immediata, ja que no √©s determinista i continua variant les accions fins i tot sense dades noves.


---

### Resum comparatiu per a l'examen

| **Algorisme** | **Tipus de tria** | **Punt fort**                                   |
| ------------- | ----------------- | ----------------------------------------------- |
| **Softmax**   | Probabil√≠stica    | F√†cil de tunar amb la temperatura ($\tau$).     |
| **UCB1**      | Determinista      | Molt s√≤lid estad√≠sticament (cota de Hoeffding). |
| **Thompson**  | Estoc√†stica       | Supera UCB quan la retroalimentaci√≥ es retarda. |

|**Caracter√≠stica**|**Softmax**|**Thompson Sampling**|
|---|---|---|
|**Naturalesa**|Probabil√≠stica basada en valor estimat.|Estoc√†stica basada en distribucions.|
|**Par√†metre clau**|Temperatura ($\tau$).|Par√†metres de forma ($\alpha, \beta$).|
|**Punt fort**|Simple de controlar el balan√ß exploraci√≥/explotaci√≥.|Gestiona molt b√© la incertesa i el retard en les dades.|

### OJO AMB NO ESTACIONARIS
La resposta curta √©s: **no √©s que el Softmax sigui "pitjor" per si mateix, sin√≥ que la seva efic√†cia dep√®n de com gestionem les estimacions i la incertesa.**

En un escenari **no estacionari** (on la distribuci√≥ de recompenses varia amb el temps), el rendiment de qualsevol algorisme canvia dr√†sticament. Aqu√≠ tens la comparativa t√®cnica segons la teoria:

---

### 1. El problema de la mitjana simple

Tots els m√®todes d'acci√≥-valor (incl√≤s el Softmax) fallen en problemes no estacionaris si utilitzen la **mostra promitjada** (mitjana simple).

- **Per qu√®?** Perqu√® la mitjana simple d√≥na el mateix pes a una recompensa obtinguda fa 1.000 jugades que a una obtinguda ara mateix.
    
- **La soluci√≥:** Cal usar una **mida de pas constant** ($\alpha$). Amb aquesta formulaci√≥ incremental, les recompenses m√©s recents tenen m√©s pes i les antigues decreixen exponencialment.
    

$$Q_{k+1} = Q_k + \alpha (r_{k+1} - Q_k)$$

---

### 2. Softmax vs. M√®todes d'Incertesa (UCB i Thompson)

Tot i que podem adaptar el Softmax amb $\alpha$, els m√®todes que incorporen la **incertesa** solen ser superiors en la immensa majoria de casos.

- **Softmax (Limitaci√≥):** Explora de forma probabil√≠stica basant-se nom√©s en el valor estimat. Si una acci√≥ que era dolenta de sobte es torna bona (canvi no estacionari), el Softmax pot trigar molt a "redescobrir-la" si la seva temperatura $\tau$ √©s baixa.
    
- **UCB1 (Avantatge):** Incorpora la incertesa estad√≠sticament. Si una acci√≥ no s'ha provat durant molt de temps, el seu terme d'incertesa $\sqrt{2 \ln t / t_a}$ creix, obligant l'algorisme a re-explorar-la autom√†ticament.
    
- **Thompson Sampling (El guanyador):** √âs especialment efica√ß en sistemes reals i quan la retroalimentaci√≥ es retarda. Com que √©s **estoc√†stic** (mostreja una distribuci√≥), mant√© una exploraci√≥ m√©s din√†mica i adaptativa que el Softmax pur.
    

---

### üìä Resum comparatiu en entorns no estacionaris

|**Algorisme**|**Adaptabilitat**|**Comportament davant canvis**|
|---|---|---|
|**Softmax**|Mitjana|Dep√®n totalment de la temperatura $\tau$ i de l'√∫s d'una $\alpha$ constant.|
|**UCB1**|Alta|Molt bo perqu√® la incertesa creix per a les accions no visitades.|
|**Thompson**|**Molt Alta**|El millor en casos complexos i amb retards en les dades.|

> [!IMPORTANT] En resum: 
> El Softmax √©s "pitjor" perqu√® √©s un m√®tode **cec a la incertesa**. Mentre que UCB i Thompson saben quina part del seu coneixement √©s "vell" o "incert", el Softmax nom√©s mira quina opci√≥ t√© millor puntuaci√≥ en aquell moment.


---
# Bayes
El Teorema de Bayes √©s una eina fonamental per a qualsevol analista de dades, ja que permet actualitzar la nostra confian√ßa en una hip√≤tesi a mesura que obtenim noves evid√®ncies.

### 1. Creences vs. Freq√º√®ncies

La gran difer√®ncia entre l'estad√≠stica cl√†ssica (freq√ºentista) i la bayesiana √©s la definici√≥ de "probabilitat":

- **Punt de vista Freq√ºentista:** 
	- Interpreta la probabilitat com la freq√º√®ncia d'esdeveniments a llarg termini en una s√®rie d'assaigs repetibles. 
	- Per a un freq√ºentista, no existeix la "probabilitat" que Bin Laden estigui mort: o ho est√† o no ho est√†, perqu√® no √©s un esdeveniment que puguis repetir mil vegades per veure quantes surt "mort".
    
- **Punt de vista Bayesi√†:** 
	- Defineix la probabilitat com el **grau de creen√ßa** o confian√ßa que tenim en qu√® un esdeveniment es produeixi. 
	- Aix√≤ ens permet assignar un valor num√®ric a la nostra incertesa basant-nos en el nostre estat de coneixement actual.
    

### 2. L'exemple de Bin Laden

En el cas de Bin Laden, el bayesianisme √©s l'√∫nica eina que ens permet operar amb rigor:

- Com que no hi ha s√®ries d'assaigs id√®ntics, la noci√≥ cl√†ssica de probabilitat no s'aplica.
    
- Un analista bayesi√† pot dir: "Amb la informaci√≥ d'intel¬∑lig√®ncia que tinc ara (evid√®ncies), la meva confian√ßa en la hip√≤tesi que est√† mort √©s del 80%".
    
- Aquest estat de coneixement es **modifica** immediatament quan apareix nova informaci√≥ (per exemple, un v√≠deo nou o una prova d'ADN).
    

### 3. La Interpretaci√≥ Diacr√≤nica (Actualitzaci√≥)

La utilitat fonamental de la f√≥rmula √©s que ens d√≥na un m√®tode objectiu per modificar les nostres hip√≤tesis en funci√≥ de les dades:

> [!TIP] **L'Ess√®ncia de Bayes** 
> Ens permet passar de $P(B|A)$ a $P(A|B)$. Aix√≤ √©s √∫til quan √©s molt dif√≠cil calcular directament el que volem saber ($P(H|D)$), per√≤ √©s f√†cil calcular com de b√© la nostra hip√≤tesi explica les dades ($P(D|H)$).

En resum, Bayes serveix per **aprendre de l'experi√®ncia**. Cada vegada que rebem una dada nova, no llencem el que sab√≠em abans, sin√≥ que ho fem servir com a "a priori" per calcular una nova "a posteriori" m√©s precisa.

## 1. Fonaments de la Teoria Bayesiana

El Teorema de Bayes es deriva de les propietats b√†siques de la probabilitat, espec√≠ficament de la probabilitat condicional i la regla de la cadena.

### Conceptes Cr√≠tics

- **Probabilitat Marginal $P(A)$:** La probabilitat que ocorri un esdeveniment independentment d'altres variables.
    
- **Probabilitat Conjunta $P(A,B)$:** La probabilitat que ocorrin $A$ i $B$ alhora.
    
- **Probabilitat Condicional $P(A|B)$:** La probabilitat que ocorri $A$ sabent que ja ha passat $B$.
    

### La F√≥rmula de Bayes

La forma general del teorema permet "invertir" les probabilitats condicionals:

$$P(H|D) = \frac{P(D|H)P(H)}{P(D)}$$

### Interpretaci√≥ Diacr√≤nica

>[!quote] Diacr√≤nica
>Proc√©s d'actualitzaci√≥ d'una hip√≤tesi o creen√ßa a mesura que es disposa de nova informaci√≥ al llarg del temps. Serveix per modificar de forma objectiva la probabilitat _a priori_ inicial i convertir-la en una probabilitat _a posteriori_ basada en les dades.

En l'an√†lisi de dades, utilitzem una terminologia espec√≠fica per descriure com canvia el nostre coneixement:

- **$P(H)$ (Priori):** El nostre grau de creen√ßa en la hip√≤tesi _abans_ de veure les dades.
    
- **$P(H|D)$ (Posteriori):** La probabilitat de la hip√≤tesi _despr√©s_ d'observar les dades.
    
- **$P(D|H)$ (Versemblan√ßa/Likelihood):** Com de b√© explica la hip√≤tesi les dades observades.
    
- **$P(D)$:** Una constant de normalitzaci√≥ que assegura que la suma de probabilitats sigui 1.
    

---

## 2. Exemple: El Test M√®dic

Aquest exemple √©s cl√†ssic perqu√® demostra com la intu√Øci√≥ humana sovint falla davant les probabilitats baixes (prevalen√ßa).

### L'Escenari

Suposem una malaltia amb les seg√ºents dades estad√≠stiques:

1. **Prevalen√ßa:** Nom√©s el **5%** de la poblaci√≥ est√† malalta ($P(H_{s√≠}) = 0,05$).
    
2. **Precisi√≥ del test:** El test t√© una fiabilitat del **90%** tant per a positius com per a negatius ($P(E_{s√≠}|H_{s√≠}) = 0,9$ i $P(E_{no}|H_{no}) = 0,9$).
    

### El Problema

Volem saber: **Si un pacient d√≥na positiu ($E_{s√≠}$), quina √©s la probabilitat real que tingui la malaltia ($H_{s√≠}$)?**

### C√†lcul

Aplicant el Teorema de Bayes i la llei de la probabilitat total per al denominador:

$$P(H_{s√≠}|E_{s√≠}) = \frac{P(E_{s√≠}|H_{s√≠})P(H_{s√≠})}{P(H_{s√≠})P(E_{s√≠}|H_{s√≠}) + P(H_{no})P(E_{s√≠}|H_{no})}$$

Substituint els valors:

- Numerador: $0,9 \times 0,05 = 0,045$
    
- Denominador (Probabilitat de donar positiu): $(0,9 \times 0,05) + (0,1 \times 0,95) = 0,045 + 0,095 = 0,14$
    

> [!IMPORTANT]
> 
> **Conclusi√≥:** Tot i que el test t√© un 90% de precisi√≥, si d√≥nes positiu, la probabilitat d'estar malalt √©s nom√©s del **32%**. Aix√≤ passa perqu√® la malaltia √©s molt rara (priori baixa) i el nombre de "falsos positius" de la gent sana (95% de la poblaci√≥) acaba superant els positius reals.



---
# Fully Connected (FC) vs. Convolutional Neural Networks (CNN)

Les xarxes **CNN** representen una evoluci√≥ creativa de les **FC** per processar dades amb estructura espacial, com les imatges.

>[!quote] MNIST
>Nomes √©s un database d'imatges de n√∫meros

# Fonaments d'Arquitectura Neuronal: Perceptr√≥, Tensor i Activaci√≥

Per entendre com una **CNN** optimitza el processament d'imatges respecte a una **FC**, cal dominar aquests tres conceptes que defineixen com viatja i es transforma la informaci√≥.

## El Perceptr√≥

El **perceptr√≥** (tamb√© anomenat unitat o neurona artificial) √©s el component fonamental que processa la informaci√≥. La seva arquitectura determina com la xarxa apr√®n i quina capacitat t√© per recon√®ixer patrons.

### 1. Estructura i Funcionament Matem√†tic

Cada perceptr√≥ opera seguint una seq√º√®ncia l√≤gica de c√†lcul que transforma les dades d'entrada en una decisi√≥ o activaci√≥:

- **Entrades ($a$):** Rep els valors de la capa anterior (per exemple, la intensitat dels p√≠xels de la imatge MNIST).
    
- **Pesos ($w$):** Cada entrada t√© un pes que determina la seva import√†ncia. En les CNN, aquests pesos es visualitzen com a filtres que busquen patrons concrets.
    
- **Biaix ($b$):** Un valor addicional que permet a la neurona ajustar el seu llindar d'activaci√≥ independentment de les entrades.
    
- **Suma Ponderada:** El perceptr√≥ calcula la suma de totes les entrades multiplicades pels seus pesos m√©s el biaix: $z = b + \sum_{l=0}^{4} \sum_{m=0}^{4} w_{l,m} a_{j+l,k+m}$.
    
- **Activaci√≥ ($\sigma$):** El resultat de la suma es passa per una funci√≥ d'activaci√≥ no lineal per determinar la sortida final de la unitat.
    

### 2. El Perceptr√≥ en FC vs. CNN: Difer√®ncies de Connectivitat

La gran difer√®ncia entre arquitectures no √©s el perceptr√≥ en si, sin√≥ **com es connecta** a les dades:

#### A. Perceptr√≥ Fully Connected (FC)

- **Connectivitat Global:** Cada unitat est√† connectada a **tots** els elements de l'entrada.
    
- **C√†rrega de Par√†metres:** En una imatge de MNIST ($28 \times 28$), un sol perceptr√≥ de la primera capa oculta ha de gestionar **784 pesos** m√©s un biaix.
    
- **Limitaci√≥:** Ignora l'estructura espacial; si un patr√≥ es mou uns p√≠xels, el perceptr√≥ FC no el reconeixer√† com el mateix objecte.
    

#### B. Perceptr√≥ Convolucional (LRF - Local Receptive Field)

- **Connectivitat Local:** Inspirat en la neuroci√®ncia, cada unitat nom√©s t√© una **"visi√≥ local"** de la imatge (una submatriu, normalment de $5 \times 5$ p√≠xels).
    
- **Pesos Compartits:** Aquesta √©s la clau de la millora: tots els perceptrons d'un mateix mapa de caracter√≠stiques utilitzen els **mateixos pesos ($w$) i biaix ($b$)**.
    
- **Avantatge:** Aix√≤ permet que la xarxa detecti una caracter√≠stica (com una aresta) en qualsevol lloc de la imatge amb un nombre m√≠nim de par√†metres, aconseguint **invari√†ncia a la translaci√≥**.
![[Pasted image 20260125195302.png]]

L'**stride** (salt) determina quantes posicions es despla√ßa el filtre sobre la imatge d'entrada. Si el salt √©s d'1, el filtre avan√ßa p√≠xel a p√≠xel; si √©s de 2, se salta un p√≠xel entremig.

Aquesta t√®cnica √©s √∫til per:

- **Reduir la dimensionalitat**: En saltar p√≠xels, el "mapa de caracter√≠stiques" resultant √©s m√©s petit, el que accelera el c√†lcul.
    
- **Efici√®ncia de par√†metres**: Com que hi ha menys unitats a la capa de sortida, es redueix la quantitat total de pesos i biaixos necessaris.
    
- **Eliminar redund√†ncia**: En imatges naturals, els p√≠xels ve√Øns solen ser molt similars, per la qual cosa processar-los tots de vegades no aporta informaci√≥ extra.
![[Pasted image 20260125195632.png]]

>[!WARNING]  IMPORTANT
> LRF no funcioa b√© amb imatges naturals

>[!tip] Sharing LRF Weights
>Per a imatges el que fem √©s compartir pesos per cada pixel, en comptes de fer una convoluci√≥ independent (Per exemple Sobel)
>- Convoluci√≥ √©s multiplicar 2 matrius on s'est√†n plicant 2 funcions alhora

Tot aix√≤ pot fer que fem una reducci√≥ de dimensionalitat massa agressiva, per aix√≤ existeix el pading

![[Pasted image 20260125200148.png]]

### Qu√® √©s el Pooling?

L'objectiu principal del pooling √©s reduir la mida de les representacions interm√®dies (els mapes de caracter√≠stiques) per disminuir el nombre de par√†metres i el cost computacional de la xarxa. Aix√≤ tamb√© ajuda a fer que la detecci√≥ de patrons sigui m√©s invariant a petites distorsions o canvis de posici√≥.
#### Max Pooling

√âs el m√®tode de pooling m√©s utilitzat en arquitectures com les destinades a **MNIST**.

- **Funcionament:** La capa divideix el mapa de caracter√≠stiques en regions (normalment de $2 \times 2$) i selecciona √∫nicament el valor **m√†xim** de cada regi√≥.
    
- **L√≤gica:** S'assumeix que el valor m√©s alt representa la pres√®ncia m√©s forta d'una caracter√≠stica determinada (una aresta, un tra√ß, etc.).
    
- **Resultat:** Redueix dr√†sticament la resoluci√≥. Per exemple, una sortida de $24 \times 24$ neurones es converteix en una de $12 \times 12$ despr√©s d'un max-pooling de $2 \times 2$.
    

---

#### Average Pooling

Encara que √©s menys com√∫ en les primeres capes que el max-pooling, t√© la seva utilitat segons el tipus de dades.

- **Funcionament:** En lloc de buscar el valor m√†xim, calcula la **mitjana** aritm√®tica de tots els valors presents en la regi√≥ seleccionada.
    
- **L√≤gica:** Proporciona una visi√≥ m√©s suau i global de la regi√≥, mantenint una part de la informaci√≥ de fons que el max-pooling podria descartar.
    

---
![[Pasted image 20260125200508.png]]
## ‚öñÔ∏è Comparativa r√†pida

|**Caracter√≠stica**|**Max Pooling**|**Average Pooling**|
|---|---|---|
|**Operaci√≥**|Selecciona el valor m√†xim.|Calcula la mitjana dels valors.|
|**Focus**|Detecta les caracter√≠stiques m√©s destacades (activacions pic).|Suavitza la informaci√≥ i mant√© el context general.|
|**√ös a MNIST**|Molt com√∫ per detectar els tra√ßos definits dels n√∫meros.|Menys habitual en aquest context espec√≠fic.|

> [!NOTE] C√†rrega de Par√†metres 
> √âs fonamental recordar que les capes de pooling **no tenen par√†metres entrenables** (no hi ha pesos ni biaixos a aprendre); nom√©s apliquen una regla fixa per reduir les dimensions de les dades.

---

## üîÑ El paper en la seq√º√®ncia CNN

En una xarxa completa, el pooling actua com un pont:

1. Rep els mapes de **24x24** generats per la convoluci√≥.
    
2. Redueix la mida a **12x12**, simplificant la feina per a la seg√ºent capa.
    
3. Aquesta informaci√≥ redu√Øda √©s la que finalment s'aplana (**flattening**) per entrar al classificador final.
    

Voldries que t'ajud√©s a calcular com quedaria una matriu de $4 \times 4$ si li apliquem un Max-Pooling de $2 \times 2$ amb un salt (stride) de 2?

### 3. Capacitat i Apilament

- **M√∫ltiples respostes:** Per augmentar la capacitat del model, es calculen diversos perceptrons per a cada p√≠xel (creant diversos mapes de caracter√≠stiques) per detectar diferents patrons simult√†niament.
    
- **Jerarquia:** Quan apilem capes, els perceptrons de les capes superiors ja no miren p√≠xels, sin√≥ les activacions (caracter√≠stiques) detectades pels perceptrons de les capes inferiors, permetent una descomposici√≥ jer√†rquica de la imatge.
    

## 2. El Tensor (L'Estructura de Dades)

Un tensor √©s un contenidor num√®ric multidimensional. En el reconeixement de d√≠gits, √©s la forma en qu√® la xarxa "veu" les dades:

- **Imatges com a Tensors:** Una imatge de MNIST √©s un tensor de $28 \times 28$ p√≠xels. Si √©s en blanc i negre, √©s un tensor de 2D (o 3D amb 1 canal: $28 \times 28 \times 1$).
    
- **Pesos com a Tensors:** Els filtres de la CNN s√≥n tensors (ex. un filtre de $5 \times 5$). Els pesos d'una capa convolucional es visualitzen com a tensors que capturen caracter√≠stiques visuals.
    
- **Operaci√≥ de Flattening:** √âs el proc√©s de col¬∑lapsar un tensor multidimensional en un de sola dimensi√≥ (vector) per poder entrar-lo a les capes final de classificaci√≥.
    

## 3. La Funci√≥ d'Activaci√≥ (La Necessitat de la No-Linealitat)

Aquesta funci√≥ √©s el pas final dins de cada perceptr√≥ i √©s descrita com a **"estrictament necess√†ria"** per al funcionament de la xarxa.

### Per qu√® la necessitem?

- **No-linealitat:** Sense ella, una xarxa (per moltes capes que tingu√©s) es comportaria com una simple operaci√≥ lineal. No podria aprendre patrons complexos com les corbes o els tra√ßos d'un n√∫mero manuscrit.
    
- **Decisi√≥:** Ajuda a la xarxa a decidir quina informaci√≥ √©s rellevant i ha de passar a la seg√ºent capa.
    

### Tipus i Difer√®ncies (Segons la teoria MNIST)

La teoria utilitza el s√≠mbol **$\sigma$** per representar aquesta funci√≥. Tot i que n'existeixen moltes, les m√©s habituals s√≥n:

1. **Sigmoide ($\sigma$):**
    
    - **Qu√® fa:** Comprimeix qualsevol valor d'entrada en un rang entre 0 i 1.
        
    - **√ös:** Hist√≤ricament molt utilitzada, especialment en les capes de sortida per a probabilitats.
        
2. **ReLU (Rectified Linear Unit):**
    
    - **Qu√® fa:** Si l'entrada √©s negativa, la converteix en 0. Si √©s positiva, deixa el valor tal qual.
        
    - **Difer√®ncia:** √âs molt m√©s r√†pida de calcular que la sigmoide i ajuda a evitar problemes de gradient en xarxes profundes.
        
3. **Softmax:**
    
    - **√ös:** T√≠pica de la capa final en classificaci√≥ (com predir si un d√≠git √©s un 5 o un 8). Converteix les sortides en una distribuci√≥ de probabilitat que suma 1.
        

---

## Connexi√≥ Conceptual

En una **CNN**, el **tensor** d'entrada √©s processat per **perceptrons** amb camps receptius locals que apliquen una **funci√≥ d'activaci√≥** $\sigma$. Aquesta combinaci√≥ permet que la xarxa detecti caracter√≠stiques jer√†rquiques (arestes, despr√©s formes, despr√©s n√∫meros) de manera molt m√©s eficient que una xarxa FC.


## 1. Per qu√® la CNN √©s millor que la FC en imatges?

Les xarxes **Fully Connected (FC)** presenten dos problemes cr√≠tics quan escalem a imatges reals:

- **Explosi√≥ de par√†metres:** 
	- En una FC, cada neurona est√† connectada a **tots** els p√≠xels de l'entrada. 
		- Per a una imatge d'1 megapixel ($10^6$), fins i tot una capa oculta petita de $1.000$ unitats requeriria $10^9$ par√†metres. 

>[!fail] Problema
>Aix√≤ fa que el model sigui ineficient i requereixi conjunts de dades enormes per no sobreajustar-se.

- **P√®rdua d'estructura (Flattening):** 
	- Per entrar una imatge a una FC, primer cal fer una operaci√≥ de **flattening** (aplanament), col¬∑lapsant la matriu 2D en un vector d'una dimensi√≥. Aix√≤ destrueix la relaci√≥ espacial entre p√≠xels ve√Øns.

>[!fail] Problema
>Aix√≤ fa que els pixels perdin el context dels veins (super important)

### Com ho soluciona la CNN?

La CNN explota l'estructura de les imatges mitjan√ßant tres conceptes:

1. **Camps Receptius Locals (LRF):** Les neurones nom√©s miren una petita subregi√≥ de la imatge ($f \times f$), anomenada camp receptiu local.
    
2. **Pesos Compartits:** Totes les unitats d'un "mapa de caracter√≠stiques" utilitzen exactament els mateixos pesos i biaix. Aix√≤ permet la **invari√†ncia a la translaci√≥**: si un patr√≥ (com una aresta) apareix en qualsevol lloc de la imatge, el mateix filtre el detectar√†.
    
3. **Pooling:** Simplifica la informaci√≥ de sortida de les capes convolucionals, reduint la dimensi√≥ i mantenint les caracter√≠stiques m√©s importants.

>[!info] √âs a dir
>Agafem cada pixel i li apliquem una convoluci√≥, permetent que mantingui context i reduim dimensionalitat

---

## 2. Teoria de Par√†metres (per a Tensorflow Playground)

Entendre el c√†lcul de par√†metres √©s clau per saber quants pesos estem entrenant realment.

### Capa Fully Connected (FC)

Cada connexi√≥ √©s un pes independent.

- **F√≥rmula:** $(\text{entrades} \times \text{unitats}) + \text{biaixos}$.
    
- _Exemple MNIST:_ Una capa FC amb 5 unitats i entrada de 784 p√≠xels t√© $(784 \times 5) + 5 = 3.925$ pesos.

### Capa Convolucional (CNN)

Aqu√≠ el nombre de par√†metres no dep√®n de la mida de la imatge d'entrada, sin√≥ de la mida del filtre.

- **F√≥rmula:** $(\text{filtre}_w \times \text{filtre}_h \times \text{canals\_entrada} \times \text{mapes\_caracter√≠stiques}) + \text{biaixos}$.
    
- _Exemple:_ Un filtre de $5 \times 5$ per a una imatge BN (1 canal) amb 3 mapes de caracter√≠stiques nom√©s t√© $(5 \times 5 \times 1 \times 3) + 3 = 78$ par√†metres.
    

> [!NOTE] C√†lcul de dimensions de sortida 
> - Sense padding, la dimensi√≥ de sortida d'una convoluci√≥ √©s $(n - f + 1) \times (n - f + 1)$, on $n$ √©s el costat de la imatge i $f$ el del filtre. 
> - El **padding** s'utilitza per evitar que la imatge s'encongeixi massa r√†pidament i permetre xarxes m√©s profundes.

---

## 3. Seq√º√®ncia i Passos d'una CNN (Exemple MNIST)

Per a un examen, √©s vital con√®ixer l'ordre l√≤gic del processament:

1. **Entrada (Input):** Imatge original (ex. $28 \times 28$ p√≠xelsBN).
    
2. **Capa Convolucional:** S'apliquen $k$ filtres (ex. 3 mapes amb LRF de $5 \times 5$). Resultat: $3$ mapes de $24 \times 24$ (si no hi ha padding).
    
3. **Activaci√≥ No Lineal:** S'aplica una funci√≥ (com ReLU) a cada activaci√≥ (tot i que sovint s'omet en diagrames per simplicitat).
    
4. **Capa de Pooling (Max-Pooling):** Redueix la mida dels mapes (ex. de regions $2 \times 2$ agafa el valor m√†xim). Resultat: $3$ mapes de $12 \times 12$.
    
5. **Aplanament (Flattening):** Es converteixen els mapes 2D finals en un vector 1D (ex. $3 \times 12 \times 12 = 432$ unitats).
    
6. **Capa Fully Connected (Classifier):** Aquest vector s'envia a una o m√©s capes FC per realitzar la classificaci√≥ final (ex. 10 unitats per als d√≠gits del 0 al 9).

![[Pasted image 20260125200607.png]]

L'**apilament** (stacking) d'aquestes capes permet que la xarxa aprengui una descomposici√≥ jer√†rquica de la imatge, des d'arestes simples fins a formes complexes.
![[Pasted image 20260125200629.png]]

---


# GEN AI
## Entrenament de Models de Llenguatge Extens (LLM)

L'objectiu fonamental d'un model de llenguatge √©s actuar com un **model probabil√≠stic autoregressiu**. Aix√≤ implica que el model apr√®n a calcular la probabilitat d'una seq√º√®ncia de s√≠mbols (tokens) i, donada una cadena, predir el token m√©s probable que la segueix.

### 1. Conceptes Fonamentals

Abans de l'entrenament, cal entendre com es tracten les dades:

- **Tokenitzaci√≥:** El text es descompon en unitats b√†siques anomenades tokens (paraules, subparaules o car√†cters) mitjan√ßant un algoritme predefinit que els converteix en nombres enters d'un vocabulari fix.
![[Pasted image 20260125201938.png]]

- **Arquitectura:** Els LLM actuals s√≥n xarxes neuronals de gran capacitat basades en l'arquitectura **Transformer**, amb bilions de par√†metres ($\theta$).
    

### 2. Fase I: Pre-entrenament (Pre-training)

En aquesta fase, el model adquireix coneixement general a partir de col¬∑leccions massives de dades (bilions de tokens).

- **Objectiu:** Maximitzar la probabilitat que el model assigna a la paraula real de la mostra donat el seu context anterior.
    
- **Funci√≥ d'Optimitzaci√≥:** S'utilitza la log-versemblan√ßa: $\max_{\theta} \sum \log p_{\theta}(w_t | w_{<t})$.
    
- **Funci√≥ de P√®rdua:** Es minimitza l'**entropia creuada** (_cross-entropy loss_), que √©s equivalent a maximitzar la probabilitat esmentada.
    
- **Algoritme:** S'utilitza el **descens del gradient** de forma iterativa per modificar els pesos de la xarxa i reduir l'error.
    

>[!tip] Qu√® tenim ara?
>Tenim una IA capa√ß d'escriure text, per√≤ no √©s capa√ß de seguir indicacions del usuari, Per√≤ falta m√©s passos per tenir una bona base

![[Pasted image 20260125202033.png]]
### 3. Fase II: Ajustament F√≠ Supervisat (SFT)

El model pre-entrenat sap predir tokens, per√≤ no necess√†riament seguir instruccions √∫tils. El **Supervised Fine Tuning (SFT)** el converteix en un "model instru√Øt".

- **Dades:** Es fan servir parelles de (instrucci√≥/prompt, resposta ideal) creades normalment per humans.
    
- **Proc√©s:** Es torna a entrenar el model amb aquest conjunt de dades de qualitat utilitzant la mateixa funci√≥ de p√®rdua d'entropia creuada per for√ßar el model a imitar el format i el to desitjats.

Aix√≤ crea datasets com:
![[Pasted image 20260125202145.png]]

### 4. Fase III: Aprenentatge per Refor√ß (RLHF)

Aquesta fase final ajusta el model a les prefer√®ncies humanes complexes que s√≥n dif√≠cils de codificar en regles simples.

- Anirem fent varies respostes i intentarem anar-nos ajustant a les que m√©s agraden

1. **Creaci√≥ del Model de Recompensa (RM):** Es generen diverses respostes per a un mateix prompt i humans les classifiquen segons la seva qualitat. Una xarxa neuronal separada (RM) apr√®n a predir aquestes prefer√®ncies.
![[Pasted image 20260125202339.png]]


2. **Optimitzaci√≥ de Pol√≠tiques:** S'utilitza el RM per entrenar l'LLM-SFT mitjan√ßant algorismes com l'**Optimitzaci√≥ de Pol√≠tiques Proximals (PPO)** o **GRPO**. L'objectiu √©s que l'LLM generi respostes que obtinguin la m√†xima puntuaci√≥ del RM.
   
![[Pasted image 20260125202424.png]]
### 5. M√®todes de Generaci√≥ i Mostreig (inferencia)

Un cop entrenat, per generar text s'utilitzen par√†metres que controlen l'estocasticitat (aleatorietat) del model:

- **Temperatura ($T$):** Reescala les probabilitats. Una $T > 1$ aplana la distribuci√≥ (m√©s creativitat), mentre que una $T < 1$ la fa m√©s picada (m√©s determinisme).
    ![[Pasted image 20260125202610.png]]
- **Top-k Sampling:** El model nom√©s tria entre els $k$ tokens m√©s probables.
    ![[Pasted image 20260125202532.png]]
- **Top-p (Nucleus) Sampling:** Es tria el conjunt m√≠nim de tokens que sumen una probabilitat acumulada $p$.
    ![[Pasted image 20260125202551.png]]

### 6. Xatbots
Per tenir un xatbot, i per tant un agent,  aquests tenen pol√≠tiques dins del proc√®s.
Entre altres Est√† el anar guardant la conversa
![[Pasted image 20260125202844.png]]

#### Qu√® √©s un agent:
Un **agent** √©s un sistema que utilitza un LLM com a **motor de raonament** central per completar tasques complexes mitjan√ßant l'autonomia i l'√∫s d'eines externes.

A difer√®ncia d'un LLM est√†ndard, que nom√©s prediu el seg√ºent token, un agent t√© la capacitat de planificar i interactuar amb el m√≥n real.

##### 1. L'Arquitectura d'un Agent

Podem visualitzar un agent com un sistema amb quatre components principals:

- **Cervell (El LLM):** Actua com el nucli de control. Planifica els passos i decideix quines accions prendre.
    
- **Planificaci√≥ (Planning):** L'agent desglossa una tasca gran en sub-tasques m√©s petites i manejables (t√®cniques com _Chain of Thought_).
    
- **Mem√≤ria (Memory):**
    
    - _Mem√≤ria a curt termini:_ El context de la conversa actual.
        
    - _Mem√≤ria a llarg termini:_ L'√∫s de bases de dades vectorials (RAG) per recuperar informaci√≥ externa.
        
- **Eines / √ös de recursos (Tool Use):** La capacitat de cridar APIs externes, consultar una base de dades SQL, fer c√†lculs matem√†tics exactes o navegar per la web.
    

---

##### 2. El Cicle de Raonament: ReAct

La teoria destaca el patr√≥ **ReAct** (_Reason + Act_). En lloc de respondre directament, l'agent segueix un bucle iteratiu:

1. **Pensament (Thought):** El model descriu qu√® creu que ha de fer.
    
2. **Acci√≥ (Action):** El model tria una eina (ex: `cerca_google("preu Nvidia avui")`).
    
3. **Observaci√≥ (Observation):** L'agent rep el resultat de l'eina (el "feedback" del m√≥n real).
    
4. **Actualitzaci√≥:** L'agent torna al pas 1 fins que la tasca est√† completada.
    

---

##### 3. Difer√®ncies Clau

|**Caracter√≠stica**|**LLM Est√†ndard (Chatbot)**|**Agent**|
|---|---|---|
|**Objectiu**|Generar text coherent|Completar una tasca (Goal-oriented)|
|**Interacci√≥**|Limitada al xat|Interactua amb programari extern|
|**Raonament**|Passiu (una sola passada)|Actiu i iteratiu|
|**Limitacions**|Coneixement tancat|Pot buscar dades actualitzades|

> [!TIP]
> 
> Un LLM es converteix en agent quan li passes el control d'un bucle `while`: "Mentre la tasca no estigui acabada, pensa, actua i observa".


### 6. Limitacions i Precaucions

Tot proc√©s d'entrenament pot heretar o generar problemes que cal supervisar:

- **Al¬∑lucinacions:** Generaci√≥ de fets inventats amb aparen√ßa de veritat.
    
- **Biaixos:** El model pot perpetuar estereotips presents en les dades d'entrenament.
    
- **Sobre-estimaci√≥ (_Overfitting_):** Risc de trobar un model que s'ajusti massa a les dades d'entrenament per√≤ no generalitzi b√©.


 
## ‚úçÔ∏è T√®cniques i Exemples de Prompts

El document destaca que els models responen millor quan se'ls d√≥na una estructura clara i context.

### Estrat√®gies clau amb exemples:

- **Definici√≥ de Rol:** Actuar com un expert millora la qualitat.
    
    - _Exemple:_ "Actua com un professor de programaci√≥ i explica‚Äôm Python amb exemples simples."
        
- **Especificitat i Format:** Evitar vagueses i demanar estructures concretes (JSON, llistes).
    
    - _Exemple:_ "Explica‚Äôm en 5 punts els avantatges del m√®tode bootstrap en estad√≠stica aplicada."
        
- **Raonament (Chain-of-Thought):** Demanar que el model pensi pas a pas ajuda en problemes complexos.
    
    - _Exemple:_ "Raona pas a pas i explica per qu√® descartes opcions."
        

---

## üß± L'Estructura del Prompt Modular

La pr√†ctica professional moderna divideix el prompt en 5 m√≤duls essencials per maximitzar la precisi√≥:

|**M√≤dul**|**Descripci√≥**|**Exemple del PDF**|
|---|---|---|
|**Context**|Qui ets i qu√® saps.|"S√≥c estudiant de 3er d‚ÄôInform√†tica... no conec l‚Äôaprenentatge profund."|
|**Objectiu**|Qu√® vols aconseguir.|"Necessito una explicaci√≥ clara... per explicar-la a classe."|
|**Tasques**|Accions concretes.|"Explica qu√® √©s un LLM en 6‚Äì8 frases. Inclou una analogia."|
|**Restriccions**|Qu√® s'ha d'evitar.|"No facis servir equacions avan√ßades. No donis info hist√≤rica."|
|**Format**|Com vols la sortida.|"Respon organitzat en 4 seccions: A, B, C i D."|
